'''SIMPLE TEXT CLASSIFIER USING LSTM NEURAL NETWORKS
   AND MINING OF NEW DATA AS THE TEST DATA SET'''

# -*- coding: utf-8 -*-
"""Landscape_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/thedataninja1786/1f5c7fb7470342c879506172b8f03342/landscape_classification.ipynb
"""

#Installing the required modules
!pip install bs4 
!pip install requests

#Importing the required modules
import requests 
from bs4 import BeautifulSoup 
from urllib.parse import urljoin 
import os 
import time   
import shutil 
import random

#Mounting the drive
from google.colab import drive
drive.mount('/content/drive')
print(os.getcwd())

"""Creating the directories for each category"""

folder = 'classification_data'
samples = ['train','test']
categories =['dunnes with grass', 'desert dunnes', 'fields of grass']

os.chdir(f'/content/drive/My Drive/{folder}')

main_path = f'/content/drive/My Drive/{folder}'
for sample in samples:
  if not os.path.exists(sample):
    os.mkdir(sample)
    path = os.path.join(main_path, sample)
    os.chdir(path)
    for category in categories:
      if not os.path.exists(category):
        os.mkdir(category)
    os.chdir(main_path)

"""Downloading the images"""

# The User-Agent request header contains a characteristic string that allows the network protocol peers to identify the application type, 
# operating system, and software version of the requesting software user agent needed for google search

usr_agent = {
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
    'Accept-Encoding': 'none',
    'Accept-Language': 'en-US,en;q=0.8',
    'Connection': 'keep-alive',
}

google_image_search = 'https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&'

def download_images():
  for category in categories:
    n_images = int(input(f'How many images of {category} do you want? '))

    print(f'Searching for {n_images} images of {category}.')
    search_url = google_image_search + 'q=' + category  # creating the URL query string
    #print(search_url)

    #request url, without usr_agent the permission gets denied
    response = requests.get(search_url, headers = usr_agent)

    #inspect the page and find all divs that contaign the desired class
    soup = BeautifulSoup(response.text, 'html.parser')
    results = soup.find_all('img', {'class' : 'rg_i Q4LuWd'})

    #gathering requested number of list of image links with data-src attribute
    #continue the loop in case query fails for non-data-src attributes
    count = 0
    links = []
    for result in results:
        try:
            link = result['data-src']
            links.append(link)
            count += 1
            if count >= n_images:
                break
        except:
            continue

    print(f'Downloading {len(links)} images.....')

    #access the data URI and download the image to a file
    for i, link in enumerate(links):
        response = requests.get(link)

        image_name =  'train' + '/' + category + '/' + category + str(i + 1) + '.jpg'
        with open(image_name,'wb') as file:
            file.write(response.content)

    print('Done')

download_images()

"""Allocate the images between train and test directories"""

#Create the test directories
train_directories = []
for category in categories:
  train_directories.append(f'/content/drive/My Drive/classification_data/train/{category}')

test_directories = []
for category in categories:
  test_directories.append(f'/content/drive/My Drive/classification_data/test/{category}')


#Create the test directory using a random sample from the train directory
random.seed(30) #in order to use the same images for testing the model 

for i,train_directory in enumerate(train_directories):
  files = os.listdir(train_directory)
  no_of_files = len(files) // 5
  for file in random.sample(files,no_of_files):
    shutil.move(os.path.join(train_directory,file),test_directories[i])

"""Necessary modules for training a classification algorithm """

import numpy as np 
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.metrics import categorical_crossentropy 
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from tensorflow.keras.callbacks import TensorBoard  
from sklearn.metrics import confusion_matrix 
import itertools 
import matplotlib.pyplot as plt 
import warnings 
warnings.simplefilter(action = 'ignore', category = FutureWarning)

"""###Preprocessing the images """

train_directory = '/content/drive/My Drive/classification_data/train'
test_directory = '/content/drive/My Drive/classification_data/test'

train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1/255)\
.flow_from_directory(directory = train_directory, target_size = (224,224), class_mode='categorical'\
                     , batch_size = 10)

test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1/255)\
.flow_from_directory(directory = test_directory, target_size = (224,224),class_mode='categorical'\
                     , batch_size = 10, shuffle = False)

print("train batch ", train_batches.__getitem__(0)[0].shape)
test_batches.class_indices

imgs, labels = next(train_batches)

#This function will plot images in the form of a grid with 1 row and 10 columns were images are placed 
def plotImages(images_arr):
  fig, axes = plt.subplots(1,10, figsize=(20,20))
  axes = axes.flatten()
  for img, ax in zip(images_arr,axes):
    ax.imshow(img, cmap = 'gray')
    ax.axis('off')
  plt.tight_layout()
  plt.show()

plotImages(imgs)
print(labels)

"""Training the model"""

model = Sequential([
                    keras.layers.AveragePooling2D(pool_size=(6,6),input_shape=(224,224,3)),
                    Conv2D(filters=32, kernel_size=(3,3),activation= 'relu', padding = 'same', input_shape=(224,224,3)),
                    MaxPool2D(pool_size=(2,2),strides = 2),
                    Conv2D(filters=64, kernel_size=(3,3),activation= 'relu', padding = 'same'),
                    MaxPool2D(pool_size=(2,2),strides = 2),
                    Flatten(),
                    Dense(units=3,activation='softmax'),          
])

model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy',metrics=['accuracy'])

model.fit(x=train_batches,epochs = 25, verbose = 2)

model.summary()

"""###Evaluating the results"""

model.evaluate(test_batches)
predictions = model.predict(x = test_batches, verbose = 1)

cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis = -1))

#This function is available from the TF documenation for plotting a confusion matrix of the results. 
#Normalization can be applied by setting normalize=True 

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title= 'Confusion Matrix',
                          cmap=plt.cm.Blues):

    plt.imshow(cm, interpolation = 'nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks,classes,rotation = 45)
    plt.yticks(tick_marks,classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):
      plt.text(j,i,cm[i,j]),
      horizontalalignment = 'center',
      color = 'white' if cm[i,j] > thresh else 'black'

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

#Plot a confusion matrix of the classified results
cm_plot_labels = test_batches.class_indices.keys()
plot_confusion_matrix(cm = cm, classes=cm_plot_labels, title = 'Confusion Matrix')
